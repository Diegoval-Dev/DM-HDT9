{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaa4b562",
   "metadata": {},
   "source": [
    "# Hoja de trabajo 9 Redes Neuronales Artificiales\n",
    "\n",
    "repo: https://github.com/Diegoval-Dev/DM-HDT9\n",
    "- Gerson Ramirez - 22281\n",
    "- Diego Valenzuela - 22309"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad46f20",
   "metadata": {},
   "source": [
    "## Introducción: Preparación del conjunto de datos y definición de variable respuesta\n",
    "\n",
    "En esta primera sección, trabajaremos con el mismo conjunto de datos de entrenamiento y prueba utilizado en las entregas anteriores, correspondiente al proyecto de predicción de precios de viviendas para InmoValor S.A. \n",
    "\n",
    "Seleccionaremos como variable objetivo la clasificación categórica del precio de las casas, que agrupa las propiedades en tres categorías: \"Barata\", \"Media\" y \"Cara\". Esta variable fue creada previamente a partir del precio de venta (`SalePrice`) y será utilizada en la construcción de modelos de redes neuronales para tareas de clasificación.\n",
    "\n",
    "Esta fase de preparación es fundamental, ya que asegura la coherencia y comparabilidad de resultados con los modelos previamente desarrollados como árboles de decisión, KNN, Naive Bayes, SVM, entre otros. \n",
    "La correcta definición de la variable respuesta permitirá evaluar adecuadamente el desempeño de las redes neuronales en relación con otros algoritmos explorados anteriormente.\n",
    "\n",
    "En el siguiente bloque de código cargaremos los datos procesados y seleccionaremos las variables correspondientes para iniciar la modelación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda62494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: (1460, 77)\n",
      "Dimensiones del conjunto de entrenamiento: (1168, 75)\n",
      "Dimensiones del conjunto de prueba: (292, 75)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(PriceCategory\n",
       " Intermedia    0.335616\n",
       " Economica     0.333904\n",
       " Cara          0.330479\n",
       " Name: proportion, dtype: float64,\n",
       " PriceCategory\n",
       " Intermedia    0.335616\n",
       " Cara          0.332192\n",
       " Economica     0.332192\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "df.head()\n",
    "\n",
    "X = df.drop(columns=['SalePrice', 'PriceCategory'])\n",
    "y = df['PriceCategory']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Dimensiones del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba: {X_test.shape}\")\n",
    "y_train.value_counts(normalize=True), y_test.value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bafcaab",
   "metadata": {},
   "source": [
    "## Análisis de la Preparación de Datos\n",
    "\n",
    "Para iniciar el modelado de redes neuronales, se cargó el conjunto de datos procesados, compuesto por 1460 registros y 77 variables. Se seleccionó como variable respuesta `PriceCategory`, que clasifica las viviendas en tres categorías: \"Económica\", \"Intermedia\" y \"Cara\". \n",
    "\n",
    "La variable de precio (`SalePrice`) y la categorización (`PriceCategory`) se eliminaron de las variables predictoras para evitar fuga de información.\n",
    "\n",
    "El conjunto de datos se dividió en un 80% para entrenamiento (1168 registros) y un 20% para prueba (292 registros), manteniendo la proporción de clases en ambos subconjuntos mediante estratificación. La distribución de clases resultante es equilibrada, con aproximadamente un 33% de registros en cada categoría, tanto en entrenamiento como en prueba.\n",
    "\n",
    "Esta preparación asegura que los modelos de redes neuronales se entrenen y evalúen en condiciones consistentes y comparables con los algoritmos implementados en entregas anteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d5a5df",
   "metadata": {},
   "source": [
    "## Primer Modelo de Clasificación con Redes Neuronales Artificiales\n",
    "\n",
    "En esta sección se desarrolla el primer modelo de redes neuronales artificiales (RNA) para la tarea de clasificación del precio de las viviendas en tres categorías: económica, intermedia y cara. \n",
    "\n",
    "Se implementará una red neuronal con una topología básica que incluye dos capas ocultas y una función de activación `relu` para cada capa. Como función de activación final se utilizará `softmax`, ya que se trata de un problema de clasificación multiclase.\n",
    "\n",
    "Este modelo busca establecer un punto de partida para comparar con una segunda arquitectura más compleja. Evaluaremos su desempeño con métricas comunes como la matriz de confusión y las proporciones de aciertos en cada clase. Posteriormente se contrastarán sus resultados con modelos de entregas anteriores y se analizará la posibilidad de mejorar su rendimiento mediante ajustes de hiperparámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25a2b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\diego\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5125 - loss: 1.0074 - val_accuracy: 0.6884 - val_loss: 0.6827\n",
      "Epoch 2/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7484 - loss: 0.5628 - val_accuracy: 0.7500 - val_loss: 0.5791\n",
      "Epoch 3/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.4505 - val_accuracy: 0.7637 - val_loss: 0.5428\n",
      "Epoch 4/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8618 - loss: 0.3712 - val_accuracy: 0.7637 - val_loss: 0.5258\n",
      "Epoch 5/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8745 - loss: 0.3327 - val_accuracy: 0.7774 - val_loss: 0.5189\n",
      "Epoch 6/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8924 - loss: 0.3102 - val_accuracy: 0.7740 - val_loss: 0.5187\n",
      "Epoch 7/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9058 - loss: 0.2597 - val_accuracy: 0.7705 - val_loss: 0.5152\n",
      "Epoch 8/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9241 - loss: 0.2249 - val_accuracy: 0.7671 - val_loss: 0.5140\n",
      "Epoch 9/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9312 - loss: 0.2089 - val_accuracy: 0.7808 - val_loss: 0.5223\n",
      "Epoch 10/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.1919 - val_accuracy: 0.7808 - val_loss: 0.5326\n",
      "Epoch 11/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9478 - loss: 0.1730 - val_accuracy: 0.7740 - val_loss: 0.5528\n",
      "Epoch 12/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9666 - loss: 0.1371 - val_accuracy: 0.7979 - val_loss: 0.5617\n",
      "Epoch 13/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9636 - loss: 0.1366 - val_accuracy: 0.7808 - val_loss: 0.5696\n",
      "Epoch 14/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.1150 - val_accuracy: 0.7774 - val_loss: 0.5896\n",
      "Epoch 15/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9718 - loss: 0.1185 - val_accuracy: 0.7705 - val_loss: 0.6062\n",
      "Epoch 16/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.0949 - val_accuracy: 0.7705 - val_loss: 0.6243\n",
      "Epoch 17/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9840 - loss: 0.0783 - val_accuracy: 0.7774 - val_loss: 0.6514\n",
      "Epoch 18/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.0773 - val_accuracy: 0.7740 - val_loss: 0.6687\n",
      "Epoch 19/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9841 - loss: 0.0760 - val_accuracy: 0.7808 - val_loss: 0.6727\n",
      "Epoch 20/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9891 - loss: 0.0587 - val_accuracy: 0.7774 - val_loss: 0.7018\n",
      "Epoch 21/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0602 - val_accuracy: 0.7705 - val_loss: 0.7197\n",
      "Epoch 22/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0461 - val_accuracy: 0.7774 - val_loss: 0.7485\n",
      "Epoch 23/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0401 - val_accuracy: 0.7842 - val_loss: 0.7616\n",
      "Epoch 24/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0374 - val_accuracy: 0.7808 - val_loss: 0.7594\n",
      "Epoch 25/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0410 - val_accuracy: 0.7740 - val_loss: 0.7902\n",
      "Epoch 26/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0340 - val_accuracy: 0.7740 - val_loss: 0.7978\n",
      "Epoch 27/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0311 - val_accuracy: 0.7842 - val_loss: 0.8355\n",
      "Epoch 28/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0272 - val_accuracy: 0.7774 - val_loss: 0.8393\n",
      "Epoch 29/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0230 - val_accuracy: 0.7808 - val_loss: 0.8746\n",
      "Epoch 30/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0225 - val_accuracy: 0.7740 - val_loss: 0.8781\n",
      "Epoch 31/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0180 - val_accuracy: 0.7774 - val_loss: 0.9079\n",
      "Epoch 32/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.0194 - val_accuracy: 0.7808 - val_loss: 0.8985\n",
      "Epoch 33/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9983 - loss: 0.0161 - val_accuracy: 0.7808 - val_loss: 0.9274\n",
      "Epoch 34/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0173 - val_accuracy: 0.7808 - val_loss: 0.9532\n",
      "Epoch 35/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0156 - val_accuracy: 0.7774 - val_loss: 0.9533\n",
      "Epoch 36/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0140 - val_accuracy: 0.7740 - val_loss: 0.9667\n",
      "Epoch 37/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0132 - val_accuracy: 0.7808 - val_loss: 0.9907\n",
      "Epoch 38/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0104 - val_accuracy: 0.7774 - val_loss: 1.0145\n",
      "Epoch 39/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0093 - val_accuracy: 0.7774 - val_loss: 1.0357\n",
      "Epoch 40/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0106 - val_accuracy: 0.7774 - val_loss: 1.0350\n",
      "Epoch 41/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.7774 - val_loss: 1.0517\n",
      "Epoch 42/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.7740 - val_loss: 1.0384\n",
      "Epoch 43/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.7808 - val_loss: 1.0947\n",
      "Epoch 44/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.7808 - val_loss: 1.0846\n",
      "Epoch 45/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.7808 - val_loss: 1.1003\n",
      "Epoch 46/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7808 - val_loss: 1.1190\n",
      "Epoch 47/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7774 - val_loss: 1.1159\n",
      "Epoch 48/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.7808 - val_loss: 1.1456\n",
      "Epoch 49/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.7774 - val_loss: 1.1458\n",
      "Epoch 50/50\n",
      "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.7808 - val_loss: 1.1561\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model_1.add(Dense(32, activation='relu'))\n",
    "model_1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_1 = model_1.fit(X_train_scaled, y_train_encoded, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test_encoded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ff9e6",
   "metadata": {},
   "source": [
    "## Análisis del Primer Modelo de Clasificación con Redes Neuronales\n",
    "\n",
    "El primer modelo de red neuronal artificial implementado utilizó dos capas ocultas con funciones de activación `relu`, y una capa de salida con activación `softmax`, adecuada para un problema de clasificación multiclase.\n",
    "\n",
    "Durante el proceso de entrenamiento de 50 épocas, el modelo alcanzó una exactitud de entrenamiento del 100%. Sin embargo, la exactitud en el conjunto de prueba se estabilizó en aproximadamente un 77.7% a 78.1%, mientras que la función de pérdida (`val_loss`) mostró un incremento progresivo en las últimas épocas.\n",
    "\n",
    "Este comportamiento sugiere la posible presencia de sobreajuste, ya que el modelo aprende demasiado bien los datos de entrenamiento pero no generaliza igual de bien a datos no vistos. A pesar de ello, el rendimiento alcanzado es competitivo frente a modelos de clasificación previamente implementados como KNN, SVM o Árboles de Decisión.\n",
    "\n",
    "En las siguientes secciones se analizará más detalladamente el rendimiento del modelo usando una matriz de confusión, así como la comparación con un segundo modelo de RNA con una arquitectura diferente.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
